name: "PreProcess2D"

base_dir : "/drive/dumps/multimodal-spaces"
exp_dir  : ""
  
data:
  sources: []
  process_dir: ${base_dir}/preprocess_feats
  Scannet:
    base_dir       : /drive/datasets/Scannet/
    shape_dir      : /drive/datasets/Shapenet/ShapeNetCore.v2/
    layout_dir     : /drive/datasets/SceneCAD/
    process_dir    : ${data.process_dir}/Scannet/
    processor2D    : Scannet2DProcessor
    processor3D    : Scannet3DProcessor
    mesh_subfix    : _vh_clean_2.labels.ply
    seg_subfix     : _vh_clean_2.0.010000.segs.json
    aggre_subfix   : _vh_clean.aggregation.json
    skip_frames    : 5
  
  Scan3R:
    base_dir       : /drive/datasets/Scan3R/
    process_dir    : ${data.process_dir}/Scan3R/
    processor3D    : Scan3R3DProcessor
    processor2D    : Scan3R2DProcessor
    processor1D    : Scan3R1DProcessor
    label_filename : labels.instances.align.annotated.v2.ply
    skip_frames    : 1

  MultiScan:
    base_dir       : /media/sayan/Expansion/data/datasets/MultiScan
    process_dir    : ${data.process_dir}/MultiScan
    processor3D    : MultiScan3DProcessor
    processor2D    : MultiScan2DProcessor
    processor1D    : MultiScan1DProcessor
    skip_frames    : 1
    
modality_info:
  1D  :
    feature_extractor: 
      embed_dim : 768
      model_path : 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth'
  
  2D  :
    feature_extractor:
      model     : DinoV2
      ckpt      : dinov2_vitg14
      embed_dim : 1536
    
    image:
      orig_size  : [480, 640]
      model_size : [224, 224]
      num_levels : 3
      top_k      : 10

  
  3D  :
    feature_extractor:
      model      : I2PMAE
      ckpt       : /drive/pretrained-models/pointbind_i2pmae.pt 
      embed_dim  : 384
    
    voxel_size : 0.05
    max_points_per_object : 1024
    min_points_per_object : 50

task: 
  name       : Preprocess 
  Preprocess :
    modality : '2D'
    splits   : ['train', 'val']